This project focuses on developing a machine learning model to recognize specific sign language gestures, namely the letters A, B, C, Del, Nothing, and Space.
Using a convolutional neural network (CNN) algorithm, the model is trained on 64x64 grayscale images from a custom dataset. 
The goal is to provide a reliable solution that operates from 6 PM to 10 PM, 
enabling efficient real-time video detection and image upload through a Graphical User Interface (GUI) designed with Tkinter.

Supported Python Version : Python 3.7.16

Run GUI.py file for start detection : 
![photo_2024-09-18_21-25-19](https://github.com/user-attachments/assets/d0f6e997-ceb1-4dcc-87cb-1bbe1418b15a)

![367644262-20b77de4-ccff-4590-8f86-3113871cabe4](https://github.com/user-attachments/assets/f56eb8e0-32f8-47a6-847f-be945db9645d)

